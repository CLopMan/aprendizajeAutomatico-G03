{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EDA y primer modelo - Grupo03\n",
        "### Authors\n",
        "- César López Mantecón - 100472092\n",
        "- Manuel Gómez-Plana Rodríguez - 100472310\n",
        "\n",
        "### Repositorio\n",
        "Esta práctica se ha llevado a cabo en [este repositorio de github](https://github.com/CLopMan/aprendizajeAutomatico-G03)\n"
      ],
      "metadata": {
        "id": "mGOGLgQjVSzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Índice\n",
        "...\n",
        "\n",
        "## Introducción\n",
        "En este *notebook* se recoge el Análisis de Datos Exploratorio (EDA, por sus siglas en inglés[1]) además de la selección del primer modelo. Comenzaremos por el EDA. Este proceso constará de los siguientes pasos: ajuste de datos, determinación de características e instancias, análisis de variables e instancias (estudio de la relación entre variables y existencia de valores nulos -- TODO: borrar este paréntesis) y modelización del problema.\n",
        "\n",
        "Tras el EDA, haremos un análisis de la evaluación *outer* e *inner* junto con la decisión de las métricas usadas. Luego, decidiremos el método de escalado más adecuado usando el KNN como algoritmo, para luego probar varios modelos para poder decidir cual es el mejor.\n",
        "\n",
        "Ahora, comencemos con el EDA.\n",
        "\n",
        "---\n",
        "\n",
        "[1]: IBM, \"Análisis de datos exploratorio\". IBM. https://www.ibm.com/es-es/topics/exploratory-data-analysis (acceso: 28 de febrero de 2024)"
      ],
      "metadata": {
        "id": "zBICmTJxVvwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA - 1.Ajuste de datos\n",
        "En este apartado haremos un pequeño preprocesado de los datos para eliminar la instancias que no son relevantes para el problema propuesto.\n",
        "Para ello, comenzamos importando el módulo `pandas`. Esto nos permitirá usar la herramienta de *dataframes* con el fin anterior."
      ],
      "metadata": {
        "id": "CWFi4MgXaTsw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IpjHPh2VISo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gracias a `pandas` podemos echar un primer vistazo a los datos, primero importando el csv y luego comprobando la cantidad de instancias iniciales."
      ],
      "metadata": {
        "id": "moXabDWSc6oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv = pd.read_csv(\"wind_ava.csv\")\n",
        "print(\"nº filas = \" + str(len(csv)) + \"\\nnº columnas = \" + str(len(csv.columns)))"
      ],
      "metadata": {
        "id": "kYVP5DAudScz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos que este *feature space* es un espacio 552-dimensional con 4748 instancias.\n",
        "\n",
        "A continuación, generamos un fichero cuyas columnas sean las de la localización *Sotavento*, es decir, la número 13, reduciendo las dimensiones de este *dataframe*."
      ],
      "metadata": {
        "id": "B4ZplcHXa6wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv = pd.read_csv(\"wind_ava.csv\")\n",
        "csv = csv.filter(regex='13$|energy|datetime')"
      ],
      "metadata": {
        "id": "nvjAUZmibI4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, el *feature space* disminuye a un espacio 24-dimensional, con las mismas 4748 instancias previas. Con esto, concluimos el ajuste del dataframe para reducirlo a los datos relevantes a la localización Sotavento."
      ],
      "metadata": {
        "id": "6lYVxTChRIPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA - 2.Determinación de características e instancias\n",
        "En este apartado, analizaremos los tipos de datos que conforman el *feature space*, describiendo qué valores son numéricos y cuáles categóricos. En el siguiete código, mostramos una instancia del *dataframe* para poder observar cada *feature*."
      ],
      "metadata": {
        "id": "xtHEP126R4th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_row = csv[0:1]\n",
        "first_row.to_csv(\"sample.csv\")"
      ],
      "metadata": {
        "id": "DkwuFOv4SdOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que las 24 instancias son **numéricas** en coma flotante, destacando una marca de tiempo en la columna *daytime*. Para poder visualizar mejor la información, nos hemos valido de la herramienta *LibreOffice Calc*."
      ],
      "metadata": {
        "id": "xBqtBFXYWOQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA - 3. Análisis de variables e Instancias\n",
        "\n",
        "A continuación, estudiaremos el conjunto de datos para comprobar la existencia de relaciones entre variables, con el fin de limpiar el conjunto de datos que no sean relevantes para el estudio. Para ello, primero haremos un breve análisis de los datos para comprobar la existencia de valores nulos o atípicos.\n",
        "\n",
        "### Existencia de valores nulos\n",
        "Comprobamos mediante el siguiente código que **no existen valores nulos en el set de datos** ."
      ],
      "metadata": {
        "id": "QXA_FIgbXeWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(csv)):\n",
        " for j in range(len(csv.columns)):\n",
        "  if (pd.isnull(csv.iloc[i, j])):\n",
        "    print(\"Dataframe column\", str(j), \"in row\", i,\" is null.\")"
      ],
      "metadata": {
        "id": "nHkd25gxXeGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Existencia de valores atípicos\n",
        "\n"
      ],
      "metadata": {
        "id": "HspD22MwZNET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estudio de correlaciones\n"
      ],
      "metadata": {
        "id": "sYmq781EfHRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Existencia de columnas constantes\n",
        "\n",
        "Para comprobar la existencia de columnas constantes. Debido a la naturaleza de los datos, se considerará que dos valores son distintos si difieren en más de un 1% del valor más grande. A través del siguiente código vemos que **no existen columnas constantes**."
      ],
      "metadata": {
        "id": "wD1S6Ydabuuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(0, 1, 1):\n",
        " same_date = True\n",
        " same_day = True\n",
        " i = 0\n",
        " while((same_date or same_day) and i < len(csv)-1):\n",
        "  if (csv.iloc[i, j] != csv.iloc[i+1,j]):\n",
        "   same_date = False\n",
        "  if (csv.iloc[i, j][0:10] != csv.iloc[i+1,j][0:10]):\n",
        "   same_day = False\n",
        "  i += 1\n",
        " if same_date:\n",
        "  print(\"The datetime values\", str(j), \"are constant.\")\n",
        " if same_day:\n",
        "  print(\"The values\", str(j), \"are from the same day\")\n",
        "\n",
        "for j in range(1, len(csv.columns), 1):\n",
        " same = True\n",
        " i = 0\n",
        " while (same and i < len(csv)-1):\n",
        "  if (csv.iloc[i+1, j] < 0.99*csv.iloc[i, j] or csv.iloc[i+1,j] > 1.01*csv.iloc[i,j]):\n",
        "   same = False\n",
        "  i += 1\n",
        " if same:\n",
        "  print(\"The values of the column\", str(j), \"are constant.\")"
      ],
      "metadata": {
        "id": "WRoqGHmqf5i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA - 4.Tipo de problema\n",
        "Tras estos análisis, debemos instanciar este problema como un problema de **Clasificación** o de **Regresión**. Lo primero que debemos saber para realizar esta clasificación, es saber la variable que tenemos que predecir, es decir, **energía**. Con los bloques de código anteriores, hemos visto que la energía es un valor discreto, por lo que podemos asumir que el modelo intenta resolver un problema de **Regresión**.\n",
        "\n",
        "Por esto, podemos decir, adicionalmente, que al estimar un valor según unas variables, se trata de un problema del tipo aprendizaje **atributo-valor*. Además, como tenemos los valores de **energía**, podemos decir que se trata de un problema de aprendizaje supervisado."
      ],
      "metadata": {
        "id": "vxRt7ySZ2Jyv"
      }
    }
  ]
}