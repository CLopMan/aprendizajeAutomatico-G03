{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **EDA y primer modelo - Grupo03**\n","\n","> Bloque con sangría\n","\n","\n","### **Authors**\n","- César López Mantecón - 100472092\n","- Manuel Gómez-Plana Rodríguez - 100472310\n","\n","### **Repositorio**\n","Esta práctica se ha llevado a cabo en [este repositorio de github](https://github.com/CLopMan/aprendizajeAutomatico-G03)\n"],"metadata":{"id":"mGOGLgQjVSzs"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nu9fQRegHBK","executionInfo":{"status":"ok","timestamp":1710328256541,"user_tz":-60,"elapsed":2056,"user":{"displayName":"MANUEL GOMEZ-PLANA RODRIGUEZ","userId":"05937251451620256688"}},"outputId":"d5b55664-6b0c-4fbd-c453-15b770fd0c42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## **Índice**\n","...\n","\n","## **Introducción**\n","En este *notebook* se recoge el Análisis de Datos Exploratorio (EDA, por sus siglas en inglés[1]) además de la selección del primer modelo. Comenzaremos por el EDA. Este proceso constará de los siguientes pasos: ajuste de datos, determinación de características e instancias, análisis de variables e instancias (existencia de valores nulos) y modelización del problema.\n","\n","Tras el EDA, haremos un análisis de la evaluación *outer* e *inner* junto con la decisión de las métricas usadas. Luego, decidiremos el método de escalado más adecuado usando el KNN como algoritmo, para luego probar varios modelos para poder decidir cual es el mejor.\n","\n","Ahora, comencemos con el EDA.\n","\n","---\n","\n","[1]: IBM, \"Análisis de datos exploratorio\". IBM. https://www.ibm.com/es-es/topics/exploratory-data-analysis (acceso: 28 de febrero de 2024)"],"metadata":{"id":"zBICmTJxVvwn"}},{"cell_type":"markdown","source":["# **Contexto del problema**\n","\n","Creo que podría quedar bien decir qué pretendemos hacer, cuál es la variable objetivo y demás.\n","\n","# **EDA - 1. Análisis preliminar**\n","\n","Usaremos el módulo pandas para analizar los datos. Esto nos permitirá usar la herramienta de dataframes con el fin anterior. Primero, mostraremos las primeras y últimas filas del dataframe para hacernos una idea preliminar de los datos. Además, haremos un recuento de instancias para ver las dimensiones del conjunto de datos.\n"],"metadata":{"id":"CWFi4MgXaTsw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0IpjHPh2VISo","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1710328336373,"user_tz":-60,"elapsed":662,"user":{"displayName":"MANUEL GOMEZ-PLANA RODRIGUEZ","userId":"05937251451620256688"}},"outputId":"cae217e6-c169-4bc0-fc6c-366207685767"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'wind_ava.csv.gz'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d92af2df9c98>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wind_ava.csv.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# lectura del fichero en bruto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# primeras filas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# últimas filas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;31m# error: Incompatible types in assignment (expression has type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;31m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                 handle = gzip.GzipFile(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m    751\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wind_ava.csv.gz'"]}],"source":["import pandas as pd\n","\n","raw_data = pd.read_csv(\"wind_ava.csv.gz\", compression='gzip') # lectura del fichero en bruto\n","print(raw_data.head()) # primeras filas\n","print(raw_data.tail()) # últimas filas\n","print(\"========DIMENSIONES========\")\n","print(\"nº filas = \" + str(len(raw_data)) + \"\\nnº columnas = \" + str(len(csv.columns)))"]},{"cell_type":"markdown","source":["Observamos que se trata de un conjunto de datos con **4748 instancias y 552 features** a priori numéricas. Para obtener más información del mismo haremos uso del método df.info() y del atributo df.dtypes.\n"],"metadata":{"id":"B4ZplcHXa6wM"}},{"cell_type":"code","source":["print(raw_data.info())\n","print(raw_data.dtypes)"],"metadata":{"id":"nVf8QbFsUtlf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","Gracias a esta información, sabemos 551 de las 552 features son de tipo numérico (concretamente, números en coma flotante de doble precisión). Además, vemos que datetime es la única característica no numérica. No obstante, al modelar una marca de tiempo se podría convertir a numérica si fuera necesario. Observamos también que, a escepción de energy y datetime, las variables se pueden relacionar fácilmente con la localización a la que hacen referencia a través del nombre de la columna en el dataframe. Con esto, concluímos esta sección con un breve resumen de las conclusiones extraídas.\n","\n","- El conjunto de datos cuenta con 4748 instancias.\n","- Cada instancia cuenta con 551 características del tipo numérico y un objeto str fácilmente convertible a numérico.\n","- Los datos están ligados a una localización fácilmente observada en el nombre de la columna.\n","\n"],"metadata":{"id":"OPRn79ZvUrQm"}},{"cell_type":"markdown","source":["# **EDA - 2.Ajuste y primer análisis de datos**\n","\n","En este apartado haremos un pequeño preprocesado de los datos para eliminar la instancias que no son relevantes para el problema propuesto. Para ello, eliminaremos todos los datos que no hagan referencia a la localización \"Sotavento\". Además, volvemos a imprimir información sobre el dataframe transformado para observar los cambios después de esta operación.\n"],"metadata":{"id":"xtHEP126R4th"}},{"cell_type":"code","source":["sotavento = raw_data.filter(regex='13$|energy|datetime') # eliminacion de instancias no referentes a Sotavento\n","\n","print(sotavento.info())\n","print(sotavento.dtypes)"],"metadata":{"id":"DkwuFOv4SdOX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comprobamos que este feature space es un espacio 24-dimensional con 4748 instancias. Al filtrar otras localizaciones hemos reducido drásticamente el número de variables a tener en cuenta. En la salida del código anterior también podemos observar que **no existen valores nulos en ninguna instancia** ya que el valor `Non-Null Count es igual al número de instancias para todas las variables [*].\n","\n","[] *Nota: téngase en cuenta que, dependiendo del tamaño de la pantalla y el visualizador del notebook* la salida del código anterior puede haber sido truncada. Recomendamos copiar la salida a un visualizador de texto cualquiera para poder observarla sin problemas.*\n"],"metadata":{"id":"xBqtBFXYWOQK"}},{"cell_type":"markdown","source":["## **EDA - 3. Análisis de variables e Instancias**\n","\n","A continuación, estudiaremos el conjunto de datos para comprobar la existencia de relaciones entre variables, con el fin concer en profundidad el conjunto de datos, así como de de limpiarlo de variables que no sean relevantes para el estudio. Para ello, analizaremos en profundidad cada instancia con el fin de detectar valores atípicos y la existencia de correlación entre las mismas o con la variable objetivo. Primero, extraeremos un conjunto de estadísticas descriptivas del conjunto de datos:"],"metadata":{"id":"QXA_FIgbXeWP"}},{"cell_type":"code","source":["print(sotavento.describe())"],"metadata":{"id":"nHkd25gxXeGG","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"error","timestamp":1710325366420,"user_tz":-60,"elapsed":411,"user":{"displayName":"MANUEL GOMEZ-PLANA RODRIGUEZ","userId":"05937251451620256688"}},"outputId":"a6a16a8d-4f31-4074-b4e6-2f3d6a1edc18"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'csv' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b7feff1e6791>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataframe column\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in row\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" is null.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"]}]},{"cell_type":"markdown","source":["En la tabla anterior podemos observar la media; desviación estándar; mínimo; valores del primer, segundo y tercer cuartil; y máximo de cada una de las features. Para complementar estos datos se han generado diferentes gráficos de cada variable para tener una idea de la distribución de los datos. Para la generación de gráficas nos valdremos de los módulos `mathplotlib` y `seaborn`.\n","\n","### **Diagrama de barras** (Aquí metería diagrama de distribuciones de los datos, más que diagramas de barras.)"],"metadata":{"id":"HspD22MwZNET"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","plt.figure(figsize=(10, 6))\n","\n","columns = list(sotavento.columns)\n","columns.remove('datetime') # no relevante, marca de tiempo\n","\n","for _ in columns:\n","    sns.histplot(sotavento[_], kde=True)\n","    plt.title(str(_))\n","    plt.show()"],"metadata":{"id":"CxWP9woDV0c9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Existencia de valores atípicos**"],"metadata":{"id":"sYmq781EfHRC"}},{"cell_type":"markdown","source":["### **Estudio de correlaciones**\n","\n","Para representar la correlación entre las variables, usaremos un mapa de color. Para ello, necesitamos representar la fecha, el único objeto que no es numérico, como un datetime."],"metadata":{"id":"yxUSjB50fqrB"}},{"cell_type":"code","source":["sotavento[\"datetime\"] = pd.to_datetime(sotavento[\"datetime\"])\n","\n","plt.figure(figsize= (20, 12))\n","correlation = sotavento.corr()\n","\n","for col in correlation.columns:\n","\tcorrelation[col] = correlation[col].round(2)\n","\n","sns.heatmap(correlation, annot=True, cmap=\"YlGnBu\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"XH6TVZsilXca","executionInfo":{"status":"error","timestamp":1710330063315,"user_tz":-60,"elapsed":329,"user":{"displayName":"MANUEL GOMEZ-PLANA RODRIGUEZ","userId":"05937251451620256688"}},"outputId":"72406941-421e-4030-b313-121d4d82f3d9"},"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'sotavento' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-144de1eb5a13>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msotavento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msotavento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msotavento\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sotavento' is not defined"]}]},{"cell_type":"markdown","source":["### **Existencia de columnas constantes**\n","\n","Para comprobar la existencia de columnas constantes. Debido a la naturaleza de los datos, se considerará que dos valores son distintos si difieren en más de un 1% del valor más grande. A través del siguiente código vemos que **no existen columnas constantes**."],"metadata":{"id":"wD1S6Ydabuuk"}},{"cell_type":"code","source":["for j in range(0, 1, 1):\n"," same_date = True\n"," same_day = True\n"," i = 0\n"," while((same_date or same_day) and i < len(sotavento)-1):\n","  if (sotavento.iloc[i, j] != sotavento.iloc[i+1,j]):\n","   same_date = False\n","  if (sotavento.iloc[i, j][0:10] != sotavento.iloc[i+1,j][0:10]):\n","   same_day = False\n","  i += 1\n"," if same_date:\n","  print(\"The datetime values\", str(j), \"are constant.\")\n"," if same_day:\n","  print(\"The values\", str(j), \"are from the same day\")\n","\n","for j in range(1, len(sotavento.columns), 1):\n"," same = True\n"," i = 0\n"," while (same and i < len(sotavento)-1):\n","  if (sotavento.iloc[i+1, j] < 0.99*sotavento.iloc[i, j] or sotavento.iloc[i+1,j] > 1.01*sotavento.iloc[i,j]):\n","   same = False\n","  i += 1\n"," if same:\n","  print(\"The values of the column\", str(j), \"are constant.\")"],"metadata":{"id":"WRoqGHmqf5i5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **EDA - 4.Tipo de problema**\n","Tras estos análisis, debemos instanciar este problema como un problema de **Clasificación** o de **Regresión**. Lo primero que debemos saber para realizar esta clasificación, es saber la variable que tenemos que predecir, es decir, **energía**. Con los bloques de código anteriores, hemos visto que la energía es un valor discreto, por lo que podemos asumir que el modelo intenta resolver un problema de **Regresión**.\n","\n","Por esto, podemos decir, adicionalmente, que al estimar un valor según unas variables, se trata de un problema del tipo aprendizaje **atributo-valor**. Además, como tenemos los valores de **energía**, podemos decir que se trata de un problema de aprendizaje supervisado.\n","\n","Una vez finalizado con el EDA, abordaremos el diseño y elección del modelo en el siguiente apartado.\n","\n"],"metadata":{"id":"nIfV5XZKfNQY"}},{"cell_type":"markdown","source":["# **Modelo - 1.Evaluaciones *outer* e *inner* y métricas**\n","En este apartado, decidiremos como llevar a cabo las evaluaciones *outer* e *inner* sobre nuestros datos. Además, pensaremos en las métricas de evaluación que usaremos para estimar el éxito de nuestro modelo.\n","\n","## **Evaluaciones *outer* e *inner***\n","\n","Lo primero a decidir para el modelo es como realizaremos las evaluaciones *inner* y *outer* para poder elegir los mejores hiperparámetros. Para ello, tenemos que pensar en los datos que tenemos.\n","\n","Sabemos que tenemos que predecir un valor discreto, **energía**, y que los datos están ordenados cronológicamente, lo cual es muy importante para decidir la evaluación *outer*. Debido a su orden, la mejor opción para realizar la evaluación outer es dividir los datos usando un *time-split*.\n","\n","Esto se debe a que queremos los datos de un año para predecir los siguientes, datos que están muy correlados entre sí, y un *cross-validator* que haga un split de los datos según series temporales es el que mejor se adecúa a esta situación. Si queremos hacer una métrica más exacta, será mejor dividir entre meses, pero eso lo decidiremos en la implementación del modelo.\n","\n","## **Métricas para la evaluación**\n","Para poder realizar la estimación de la forma más adecuada, es necesario tener en cuenta que el problema es un problema de *Regresión*. Sabiendo esto, debemos elegir una métrica que tenga en cuenta la distancia entre el punto predicho y el punto real.\n","\n","Hay múltiples opciones que podemos considerar:\n","\n","- Mean Squared Error (MSE)\n","- Mean Absolure Error (MAE)\n","- Relative Mean Squared Error (RMSE)\n","- Relative Mean Absolute Error (RMAE)\n","\n","Dada la resistencia del MAE a los valores mal predichos, e incluso a los outliers, parece ser la opción más robusta. Además, para evitar el problema de la escala de la variable respuesta, usaremos un regresor de tipo *dummy*, con el cual comparar las predicciones que hagamos. Al usar el MAE como métrica, debemos usar el *Median dummy regressor*, el cual usará la mediana de la variable respuesta."],"metadata":{"id":"vxRt7ySZ2Jyv"}}]}